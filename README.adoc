== Usage
Clone this repository and `cd` into it.

Create a virtualenv and install prerequisites:

------
$ virtualenv -p $(which python3) venv
$ . venv/bin/activate
$ pip install -r requirements.txt
------

Then run the following commands:

------
$ vagrant up
$ vagrant ssh-config
------

Based on the following template, create the `inventory/hosts` inventory file and fill it in with values for parameters `HostName`, `Port` and `IdentityFile` outputted by the last command:

======
cloudkitty-playground ansible_user=vagrant ansible_host=<IP-from-HostName> ansible_port=<number-from-Port> ansible_private_key_file=<path-from-IdentityFile>

======

[NOTE]
======
You will need to update the inventory each time you destroy the AIO VM with `vagrant destroy` and then create it again with `vagrant up`.
======

Confirm you are all set up by running:

------
$ ansible -i inventory/ all -m shell -a "hostname"
------

TODO: Find a method to generate Ansible inventories for Vagrant boxes automatically.

Next up, create this symlink (or move/copy the `kolla` subdirectory to `/etc/`) on your deploy host and deploy the OpenStack AIO with `kolla-ansible`:

------
$ sudo ln -s $(pwd)/kolla /etc/kolla
$ kolla-genpwd
$ kolla-ansible -vv -i inventory/ bootstrap-servers
$ kolla-ansible -vv -i inventory/ deploy
------

[NOTE]
======
Config files for all the deployed OpenStack services can be found in the `/etc/kolla/` directory inside the Vagrant machine.
======
When the deploy is done, run these commands to create some basic OpenStack resources:

------
$ kolla-ansible -vv -i inventory/ post-deploy
$ source /etc/kolla/admin-openrc.sh
$ wget https://opendev.org/openstack/kolla-ansible/raw/branch/stable/train/tools/init-runonce
$ EXT_NET_CIDR='172.20.20.0/24' EXT_NET_RANGE='start=172.20.20.100,end=172.20.20.200' EXT_NET_GATEWAY='172.20.20.1' bash init-runonce
------
Now you can create a test instance and SSH into it to confirm the environment is fully functional:

------
$ openstack server create --image cirros --flavor m1.tiny --key-name mykey --network demo-net demo1
$ eval $(openstack floating ip create public1 -f shell | grep ^floating_ip_address)
$ openstack server add floating ip demo1 ${floating_ip_address}
$ openstack server list
$ ssh cirros@${floating_ip_address}
------

[NOTE]
======
You may need to wait a few seconds before SSH on the instance becomes available.
======

[NOTE]
======
The Horizon dashboard URL is http://10.10.10.254.
======

To confirm CloudKitty is available, run this command on your deploy host:

------
$ cloudkitty summary get
------
This should return an empty list.

=== Replacing CloudKitty containers with host virtualenvs
For Cloudkitty testing and development it might be more convenient to work with CloudKitty installed in a virtualenv on the host rather than in containers.

------
$ vagrant ssh
$ sudo yum install python3 python3-devel gcc git vim -y
$ curl https://bootstrap.pypa.io/get-pip.py | sudo python3 -
$ pip3 install virtualenv==20.2.1
$ git clone https://opendev.org/openstack/cloudkitty
$ cd cloudkitty/
$ git checkout stable/train
$ virtualenv -p $(which python3) venv
$ . venv/bin/activate
$ pip install --upgrade pip
$ pip install -r requirements.txt
$ pip install pymysql==0.10.1 python3-memcached==1.51 # these modules are needed but not listed in requirements
$ pip install Werkzeug==0.16.1 # the latest version (1.0.1) no longer supports the "DispatcherMiddleware()" method
$ python setup.py install
$ sudo mkdir -p /opt/cloudkitty/log
$ sudo chown -R vagrant /opt/cloudkitty/
------
To replace the `cloudkitty_processor` container follow these steps:

------
$ sudo cat /etc/kolla/cloudkitty-processor/cloudkitty.conf | tee /opt/cloudkitty/cloudkitty.conf
$ sudo cat /etc/kolla/cloudkitty-processor/metrics.yml | tee /opt/cloudkitty/metrics.yml
------

[NOTE]
======
Sample `metrics.yml` files can be found on collector-specific branches in this repository.
======

Adjust paths for the following config parameters found in `/opt/cloudkitty/cloudkitty.conf`:

* `log_dir = /opt/cloudkitty/log` in section `[DEFAULT]`
* `lock_path = /opt/cloudkitty/tmp` in section `[oslo_concurrency]`
* `metrics_conf = /opt/cloudkitty/metrics.yml` in section `[collect]`

Also, remove or comment out `log_file` if present.
Finally, start the service:

------
$ sudo docker stop cloudkitty_processor
$ . venv/bin/activate
$ $(which cloudkitty-processor) --config-file /opt/cloudkitty/cloudkitty.conf
------
Processor logs will be written to `/opt/cloudkitty/log/cloudkitty-processor.log`.

To replace the `cloudkitty_api` container follow these steps:

------
$ sudo cat /etc/kolla/cloudkitty-api/cloudkitty.conf | tee /opt/cloudkitty/cloudkitty.conf
$ sudo docker exec cloudkitty_api cat /etc/cloudkitty/api_paste.ini | tee /opt/cloudkitty/api_paste.ini
------
Adjust paths for the following config parameters found in `/opt/cloudkitty/cloudkitty.conf`:

* `log_dir = /opt/cloudkitty/log` in section `[DEFAULT]`
* `lock_path = /opt/cloudkitty/tmp` in section `[oslo_concurrency]`

Also, remove or comment out `log_file` if present.
Finally, start the service:

------
$ sudo docker stop cloudkitty_api
$ . venv/bin/activate
$ $(which cloudkitty-api) --host 10.10.10.254 --port 8889 -- --config-file /opt/cloudkitty/cloudkitty.conf
------

[NOTE]
======
The port number and the host IP have to be passed through flags even if they are specified again in the `[api]` section of `cloudkitty.conf`.
======

API logs will be written to `/opt/cloudkitty/log/cloudkitty-api.log`.

== Finding CloudKitty data in Influx
Run these commands to check out what data CloudKitty has collected so far in its InfluxDB database:

------
$ sudo docker exec -it influxdb influx -host 10.10.10.254 -database cloudkitty
> SHOW MEASUREMENTS
> SELECT * FROM dataframes ORDER BY time DESC LIMIT 10
------

== Resources
. https://docs.openstack.org/cloudkitty/train/admin/configuration/collector.html
. https://docs.openstack.org/cloudkitty/train/user/rating/hashmap.html
